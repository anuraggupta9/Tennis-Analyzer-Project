{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip tennis_court_det_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class keypointDataset (Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, datafile):\n",
    "        self.dir=img_dir\n",
    "        \n",
    "        with open(datafile, 'r') as f:\n",
    "            self.data= json.load(f)\n",
    "            \n",
    "        self.transforms= transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize( mean=[.4, .4, .4] , std=[.2, .2, .2])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)  \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        item=self.data[idx] #it will read the json file\n",
    "        image= cv2.imread(f\"{self.dir}/{item['id']}.png\")     \n",
    "\n",
    "        height,width=image.shape[:2]\n",
    "        \n",
    "        image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image= self.transforms(image)\n",
    "        \n",
    "        kps=np.array(item['kps']).flatten()\n",
    "        \n",
    "        kps= kps.astype(np.float32)\n",
    "        \n",
    "        ##now the modified positions of the labels\n",
    "        \n",
    "        kps[ :: 2] *= 224/width\n",
    "        \n",
    "        kps[1:: 2] *= 224/height\n",
    "        \n",
    "        return image, kps\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = keypointDataset(\"data/images\",\"data/data_train.json\")\n",
    "valid_dataset = keypointDataset(\"data/images\",\"data/data_val.json\")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle= True)\n",
    "val_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##resnet50 is not pretrained for recognising the boundary points so last layer would be altered\n",
    "\n",
    "model=models.resnet50(pretrained = True)\n",
    "\n",
    "#last layer is a fully connected layer of 14*2 (as there are 14 kps of x and y)\n",
    "\n",
    "model.fc=torch.nn.Linear( model.fc.in_features, 14*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= torch.nn.MSELoss()\n",
    "optimizer= torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch : 1 loss = 15116.189453125\n",
      " epoch : 1 loss = 59.07713317871094\n",
      " epoch : 1 loss = 41.92870330810547\n",
      " epoch : 1 loss = 37.23984909057617\n",
      " epoch : 1 loss = 38.38298797607422\n",
      " epoch : 2 loss = 24.739696502685547\n",
      " epoch : 2 loss = 20.082767486572266\n",
      " epoch : 2 loss = 9.61832332611084\n",
      " epoch : 2 loss = 10.943277359008789\n",
      " epoch : 2 loss = 12.807669639587402\n",
      " epoch : 3 loss = 12.490171432495117\n",
      " epoch : 3 loss = 49.93429946899414\n",
      " epoch : 3 loss = 11.056880950927734\n",
      " epoch : 3 loss = 87.69979858398438\n",
      " epoch : 3 loss = 8.341574668884277\n",
      " epoch : 4 loss = 5.892822742462158\n",
      " epoch : 4 loss = 57.11442947387695\n",
      " epoch : 4 loss = 7.442975044250488\n",
      " epoch : 4 loss = 6.252378940582275\n",
      " epoch : 4 loss = 12.140094757080078\n",
      " epoch : 5 loss = 16.12542724609375\n",
      " epoch : 5 loss = 10.175070762634277\n",
      " epoch : 5 loss = 12.760015487670898\n",
      " epoch : 5 loss = 12.888014793395996\n",
      " epoch : 5 loss = 3.2263920307159424\n",
      " epoch : 6 loss = 6.822922706604004\n",
      " epoch : 6 loss = 14.233360290527344\n",
      " epoch : 6 loss = 2.604581117630005\n",
      " epoch : 6 loss = 10.282121658325195\n",
      " epoch : 6 loss = 19.532800674438477\n",
      " epoch : 7 loss = 9.898344039916992\n",
      " epoch : 7 loss = 9.644888877868652\n",
      " epoch : 7 loss = 11.425786018371582\n",
      " epoch : 7 loss = 5.930731773376465\n",
      " epoch : 7 loss = 478.4443664550781\n",
      " epoch : 8 loss = 8.03931713104248\n",
      " epoch : 8 loss = 8.742828369140625\n",
      " epoch : 8 loss = 5.246034145355225\n",
      " epoch : 8 loss = 3.255284547805786\n",
      " epoch : 8 loss = 6.65319299697876\n",
      " epoch : 9 loss = 2.7879204750061035\n",
      " epoch : 9 loss = 3.660849094390869\n",
      " epoch : 9 loss = 5.0323615074157715\n",
      " epoch : 9 loss = 9.64173698425293\n",
      " epoch : 9 loss = 9.945863723754883\n",
      " epoch : 10 loss = 6.255178451538086\n",
      " epoch : 10 loss = 3.2756974697113037\n",
      " epoch : 10 loss = 3.440373182296753\n",
      " epoch : 10 loss = 3.849435806274414\n",
      " epoch : 10 loss = 3.6878104209899902\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(10):\n",
    "    for i , (image, kps) in enumerate(train_dataloader):\n",
    "        image  = image.to(device)\n",
    "        kps = kps.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output_kps = model(image)\n",
    "        \n",
    "        loss = criterion( output_kps, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100== 0 : print(f' epoch : {epochs + 1} loss = {loss.item()}')\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"keypoints_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
